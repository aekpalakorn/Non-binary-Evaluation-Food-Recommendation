{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from src.array_util import data_to_sparse\n",
    "from src.data_io import get_dataset\n",
    "from src.io import load_pickle\n",
    "from src.models import save_model_multinomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/data/yueliu/Recommendation/data/last_basket_data' \n",
    "MODEL_DIR = '/data/yueliu/Recommendation/model'\n",
    "# train models & save the models\n",
    "save_model_multinomials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MFP47K_last basket'\n",
    "data_dir = DATA_DIR\n",
    "results_dir = MODEL_DIR\n",
    "file_name = os.path.join(DATA_DIR, dataset_name, \"item_ref.csv\")\n",
    "item_index_ref = pd.read_csv(file_name, header=None).set_index(0).to_dict()[1]\n",
    "file_name = os.path.join(DATA_DIR, dataset_name, \"user_ref.csv\")\n",
    "user_index_ref = pd.read_csv(file_name, header=None).set_index(0).to_dict()[1]\n",
    "mapping = {'user':user_index_ref, 'item':item_index_ref}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_results(dataset_name, cols, k=10):\n",
    "    user_results = defaultdict(dict)\n",
    "    train, val, test = get_dataset(dataset_name, data_dir)\n",
    "    dense_test = data_to_sparse(test).todense()   \n",
    "    all_multinomials = {model_type:load_multinomials(model_type, dataset_name) \n",
    "                    for model_type in cols}\n",
    "    \n",
    "    users = range(dense_test.shape[0])\n",
    "    for user in users:\n",
    "        user_test[dataset_name].update({user:get_test(user, dense_test)})\n",
    "        # predictions\n",
    "        for model_type in cols:\n",
    "            user_results[user].update({model_type:top_predictions(model_type, user, \n",
    "                 all_multinomials, dataset_name, k)})\n",
    "    return user_results\n",
    "\n",
    "def load_multinomials(model_type, dataset_name):\n",
    "    if model_type == 'random_model':\n",
    "        file_name = os.path.join(results_dir, 'global_model', dataset_name, 'user_multinomials.pkl')\n",
    "        shape = load_pickle(file_name).shape\n",
    "        # add up to 1\n",
    "        np.random.seed(0)\n",
    "        multi = np.random.rand(*shape)\n",
    "        multi = multi / multi.sum(axis=0)\n",
    "        return multi\n",
    "    else:\n",
    "        file_name = os.path.join(results_dir, model_type, dataset_name, 'user_multinomials.pkl')\n",
    "    return load_pickle(file_name) \n",
    "\n",
    "def get_test(user, dense_test):\n",
    "    user_test = dense_test[user].A1\n",
    "    ind_test = np.where(user_test >=1)[0]\n",
    "    return ind_test\n",
    "\n",
    "def top_predictions(model_type, user, all_multinomials, dataset_name, k):\n",
    "    user_multinomial = all_multinomials[model_type][user]\n",
    "    val = np.sort(user_multinomial)[-k]\n",
    "    ind = np.where(user_multinomial >= val)[0]\n",
    "    ranks = np.unique(-user_multinomial, return_inverse=True)[1] + 1\n",
    "    ind_test = user_test[dataset_name][user]\n",
    "    pred_true = np.isin(ind, ind_test)\n",
    "    pred = sorted(zip(ind, \n",
    "                      pred_true,\n",
    "                      ranks[ind], \n",
    "                     ), key=lambda x: x[-1])\n",
    "    return pred\n",
    "\n",
    "\n",
    "def consolidate_results(dataset_name, user_results, cols):\n",
    "    mapping = load_pickle(os.path.join(data_dir, dataset_name, \"mapping.pkl\"))\n",
    "    # original username(str):  current index in prediction(int, from 0),\n",
    "    inv_user_mapping = mapping['user']\n",
    "    inv_item_mapping = mapping['item']\n",
    "\n",
    "    df = pd.DataFrame.from_dict(user_results, orient='index')[cols]\n",
    "    df['user'] = df.index\n",
    "    df['username'] = df['user'].apply(lambda s: inv_user_mapping.get(s, -1))\n",
    "    df = df[df['username']!=-1]\n",
    "\n",
    "    df = df.melt(id_vars=['username'], value_vars=cols)\n",
    "    df = df.rename(columns={'variable':'models'})\n",
    "    df = df['value'].apply(pd.Series) \\\n",
    "        .merge(df, right_index = True, left_index = True) \\\n",
    "        .drop([\"value\"], axis = 1) \\\n",
    "        .melt(id_vars = ['username', 'models'], value_name = \"prediction\") \\\n",
    "        .drop(\"variable\", axis = 1) \\\n",
    "        .dropna()\n",
    "\n",
    "    df['item_idx'], df['is_positive'], df['pred_rank'] = zip(*df['prediction'])\n",
    "    df['item'] = df['item_idx'].apply(lambda s: inv_item_mapping.get(s, -1))\n",
    "    new_cols = ['username','models', 'pred_rank','item_idx','item', 'is_positive']\n",
    "    df = df[new_cols]\n",
    "\n",
    "    df = df.sort_values(by=new_cols).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = defaultdict(dict)\n",
    "user_results = defaultdict(dict)\n",
    "\n",
    "dataset_name = 'MFP47K_last basket'\n",
    "cols = ['random_model', 'global_model', 'personal_model', 'mixture_model', 'mixture_decay_model', \n",
    "        'nmf_model', 'wrmf_model', 'lda_model', 'bpr_model', 'fpmc_model',\n",
    "        'adaloyal_model',  'sasrec_model']\n",
    "user_results = collect_user_results(dataset_name, cols, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = consolidate_results(dataset_name, user_results, cols)\n",
    "df = df['username', 'models', 'pred_rank', 'item_idx']\n",
    "path = os.path.join('\\data\\temp\\UserStudy1', 'prediction for users.csv')\n",
    "df.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
