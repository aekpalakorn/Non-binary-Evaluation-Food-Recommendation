{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge \n",
    "\n",
    "from src.config import substitution_rating_file, preference_rating_file\n",
    "from src.config import preference_rating_scores\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "df = pd.read_csv(preference_rating_file)\n",
    "# ground truth\n",
    "df2 = pd.read_csv(substitution_rating_file)[['user', 'item_1']].drop_duplicates().reset_index(drop=True)\n",
    "df2 = df2[['user', 'item_1']]\n",
    "df2.columns = ['user', 'gt_item']\n",
    "\n",
    "gt = df2.groupby('user')['gt_item'].apply(list).to_dict()\n",
    "df['gt'] = df['user'].map(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def clean_text(s):\n",
    "    try:\n",
    "        return ' '.join(tokenizer.tokenize(re.sub(r'[^a-zA-Z ]',r'', s).lower()))\n",
    "    except:\n",
    "        print(s)\n",
    "        return ''\n",
    "\n",
    "def get_weighted_scores(single_cands, multi_refs, weights=(0.25, 0.25, 0.25, 0.25)): \n",
    "    hypothesis = word_tokenize(clean_text(single_cands))\n",
    "    reference = [word_tokenize(clean_text(ref)) for ref in multi_refs] \n",
    "    return sentence_bleu(reference, hypothesis, weights=weights)\n",
    "\n",
    "weight_scheme = {'BLEU-1':(1,0,0,0), 'BLEU-2':(0.5, 0.5, 0, 0)}\n",
    "for m, w in weight_scheme.items():\n",
    "\n",
    "    def weighted_scores(line):\n",
    "        single_cands = line['choice']\n",
    "        multi_refs = line['gt']\n",
    "        return get_weighted_scores(single_cands, multi_refs, weights=w)\n",
    "\n",
    "    df[m]= df.apply(weighted_scores, axis=1)\n",
    "\n",
    "cols = ['user', 'qn',  'rating', 'choice', 'BLEU-1', 'BLEU-2']\n",
    "df[cols].to_csv(preference_rating_scores['BLEU'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "def get_rouge_scores(single_cands, reference):\n",
    "    s = rouge.get_scores(clean_text(single_cands), clean_text(reference))[0]\n",
    "    lst = []\n",
    "    for m0 in ['rouge-1', 'rouge-2', 'rouge-l']:\n",
    "        for m in ['f', 'p', 'r']: \n",
    "            lst.append(s[m0][m])\n",
    "    return lst\n",
    "                \n",
    "def rouge_scores(line):\n",
    "    single_cands = line['choice']\n",
    "    multi_refs = line['gt_item']\n",
    "    return get_rouge_scores(single_cands, multi_refs)\n",
    "\n",
    "d = pd.merge(df2[['user', 'gt_item']], df[['user', 'qn', 'rating', 'choice']], how='outer', on=['user'])\n",
    "d['ROUGE-1_f'], d['ROUGE-1_p'], d['ROUGE-1_r'], d['ROUGE-2_f'], \\\n",
    " d['ROUGE-2_p'], d['ROUGE-2_r'], d['ROUGE-L_f'], d['ROUGE-L_p'], d['ROUGE-L_r'] = zip(*d.apply(rouge_scores, axis=1))\n",
    "\n",
    "cols = ['user', 'qn', 'rating', 'gt_item', 'choice', 'ROUGE-1_r', 'ROUGE-2_r',  'ROUGE-L_r']\n",
    "d = d[cols].rename(columns = {c:c.replace('_r', '') for c in ['ROUGE-1_r', 'ROUGE-2_r',  'ROUGE-L_r']})\n",
    "\n",
    "d.to_csv(preference_rating_scores['ROUGE'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
