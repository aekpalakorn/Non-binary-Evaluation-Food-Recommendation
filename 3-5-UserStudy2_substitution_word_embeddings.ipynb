{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bert_score import BERTScorer\n",
    "from scipy.stats import zscore\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.config import substitution_rating_file, substitution_rating_scores, substitution_score_file \n",
    "from src.config import label_file, substitution_rating_scores, weighing_scheme\n",
    "from src.config import BERT_F1_dict_file, lst_ref\n",
    "from src.io import load_pickle, save_pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43678\n"
     ]
    }
   ],
   "source": [
    "# BERT scores\n",
    "if os.path.exists(BERT_F1_dict_file):\n",
    "    sim_dict = load_pickle(BERT_F1_dict_file)\n",
    "else:\n",
    "    sim_dict = {}\n",
    "\n",
    "print(len(sim_dict))\n",
    "lst_ref = {v: k.split('__')[-1].replace('_', ' ') for k, v in lst_ref.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some name is written in the users' format for easy user reference\n",
    "def process_food_name(s1):\n",
    "    # separators: \", \" + any of (integer, decimal & fraction) +\" \"\n",
    "    exp = r\", \\d+\\.\\d+ |, \\d+\\,\\d+ |, \\d+ |, \\d+\\/\\d+ \"\n",
    "    # remove content in parenthesis for finding the separator\n",
    "    if s1.count('(') == s1.count(')'):\n",
    "        s2 = re.sub(r'[(].*?[\\)]', ' ', s1)\n",
    "    else:\n",
    "        s2 = s1\n",
    "    try:\n",
    "        split_by = re.findall(exp, s2)[0]\n",
    "        return clean_name(s1.split(split_by)[0])\n",
    "    except:\n",
    "        return clean_name(s2)\n",
    "\n",
    "def clean_name(name):\n",
    "    name = name.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"w/o\", \" no \").replace(\"w/\", \" \")\n",
    "    return re.sub(' +', ' ', name.strip()).lower()\n",
    "\n",
    "def token_transform(t):\n",
    "    tokens = [t, t+'s', t+'es']\n",
    "    if t[-1] == 'y':\n",
    "        tokens.append(t[:-1]+'ies')\n",
    "    return tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(substitution_rating_file)\n",
    "df['item_10'] = df['item_1'].apply(process_food_name)\n",
    "df['item_20'] = df['item_2'].apply(process_food_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index -> label\n",
    "labels = load_pickle(label_file)\n",
    "label_with_food = defaultdict(list)\n",
    "\n",
    "def group_food_name(line):\n",
    "    s = line['food_name']\n",
    "    for i in line['label_summary']:\n",
    "        label_with_food[i].append(s)\n",
    "\n",
    "labels.apply(group_food_name, axis=1)\n",
    "\n",
    "l0 = set(i for j in labels['label_summary'].tolist() for i in j)\n",
    "# labels['max'] = labels['label_summary'].apply(lambda s: max(s) if len(s)>0 else 0)\n",
    "\n",
    "# '_' connected tokens for l0 tags\n",
    "concat_list = list(zip(labels['cat_info'], labels['label_summary']))\n",
    "label_index = dict()\n",
    "\n",
    "for i,j in concat_list:\n",
    "    label_index.update(zip(i,j))  \n",
    "\n",
    "index_label = {k:v for v,k in label_index.items()}\n",
    "label_index_l0 = {i.split('__')[-1]:v for i,v in label_index.items() if len(i.split('__'))==3}\n",
    "l0_tags = sorted(label_index_l0.keys())\n",
    "\n",
    "label_name_l0 = {}\n",
    "\n",
    "for l,i in label_index_l0.items():\n",
    "    label_name_l0[l] = label_with_food[i]\n",
    "\n",
    "name_labels = labels.set_index('food_name').to_dict()['cat_info']\n",
    "name_label_0 = {k:[s.split('__')[-1] for s in v if len(s.split('__'))==3] for k,v in name_labels.items()}\n",
    "\n",
    "matched_label_l0, unmatched_label_l0 = [], []\n",
    "\n",
    "for l, s_lst in label_name_l0.items():    \n",
    "    l_primes = [token_transform(t) for t in l.split('_')]\n",
    "    l2 = list(itertools.product(*l_primes))\n",
    "    l_primes = [' '.join(i) for i in l2]  \n",
    " \n",
    "    matched = False\n",
    "    for s in s_lst:\n",
    "        s = ' '.join(s.replace(\"'\", '').replace('&', ' ').split())\n",
    "        for l_prime in l_primes:\n",
    "            if l_prime in s:            \n",
    "                matched = True\n",
    "            \n",
    "    if matched:\n",
    "        matched_label_l0.append(l)\n",
    "    else:\n",
    "        unmatched_label_l0.append(l)        \n",
    "\n",
    "# get all labels associated with item\n",
    "def match_labels(s):\n",
    "    if s in name_label_0.keys():\n",
    "        found = name_label_0[s] \n",
    "    else:\n",
    "        found = []\n",
    "        s = ' '.join(s.replace(\"'\", '').replace('&', ' ').split())\n",
    "        for l in matched_label_l0:\n",
    "            matched = False\n",
    "            l_primes = [token_transform(t) for t in l.split('_')]\n",
    "            for l_prime in [' '.join(i) for i in list(itertools.product(*l_primes))]:\n",
    "                if l_prime in s:  \n",
    "                    matched = True\n",
    "            if matched:\n",
    "                found.append(l) \n",
    "                        \n",
    "    # full label names\n",
    "    all_labels = []\n",
    "    if len(found) > 0:\n",
    "        full_label_l0 = [index_label[label_index_l0[l0_label]] for l0_label in found]\n",
    "        for l0 in full_label_l0:\n",
    "            l2 = l0.split('__')[0]\n",
    "            l1 = '__'.join(l0.split('__')[:2])\n",
    "            all_labels.extend([l2, l1, l0])\n",
    "    return sorted(set(all_labels))\n",
    "\n",
    "# we will use the inverse dict later in label_score() instead of lst_ref\n",
    "# Two variants: 1) using all tags along the branch; 2) using only the last tag\n",
    "inv_label_index = {v: \" \".join(k.replace(\"__\", \" \").split(\"_\")) for k, v in label_index.items()} # use all tags along the branch\n",
    "# inv_label_index = {v: \" \".join(k.split(\"__\")[-1].split(\"_\")) for k, v in label_index.items()} # use only the last tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.09162139892578\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df['item_l1'] = df['item_10'].apply(match_labels)\n",
    "df['item_l2'] = df['item_20'].apply(match_labels)\n",
    "df['l1'] = df['item_l1'].apply(lambda s: [label_index[i] for i in s] if len(s)>0 else [])\n",
    "df['l2'] = df['item_l2'].apply(lambda s: [label_index[i] for i in s] if len(s)>0 else [])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.750503540039062\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "from bert_score import BERTScorer\n",
    "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(single_cands, multi_refs):\n",
    "    P_mul, R_mul, F_mul = scorer.score([single_cands], [multi_refs])\n",
    "    return F_mul[0]\n",
    "\n",
    "def sim_score(l0, l1, sim_dict=sim_dict):\n",
    "    l0, l1 = tuple(sorted([l0, l1]))\n",
    "    \n",
    "    if (l0, l1) in sim_dict.keys():\n",
    "        return sim_dict[(l0, l1)]\n",
    "    else:\n",
    "        if l0 == l1: \n",
    "            val = 1\n",
    "        else:\n",
    "            val = get_scores(l0.lower(), l1.lower())\n",
    "        sim_dict[(l0, l1)] = val\n",
    "        return float(val)\n",
    "    \n",
    "def label_score(c_cap_j, c_cap_j_prime, weight, sim_dict=sim_dict):\n",
    "    if len(c_cap_j)==0 or len(c_cap_j_prime)==0:\n",
    "        return 0\n",
    "        #return np.nan\n",
    "    \n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for c_t in c_cap_j:\n",
    "        lambda_t = weight[c_t]\n",
    "        denominator += lambda_t\n",
    "        max_val = -1\n",
    "       \n",
    "        for c_s in c_cap_j_prime:\n",
    "            #val = sim_score(lst_ref[c_t], lst_ref[c_s], sim_dict=sim_dict)\n",
    "            val = sim_score(inv_label_index[c_t], inv_label_index[c_s], sim_dict=sim_dict)\n",
    "            #debug\n",
    "            print(\"'%s', '%s', %.4f\" % (inv_label_index[c_t], inv_label_index[c_s],val.item()))\n",
    "            if val > max_val:\n",
    "                max_val = val\n",
    "        \n",
    "        numerator += lambda_t * max_val\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8579623458539996\n",
      "0.42279067635536194\n"
     ]
    }
   ],
   "source": [
    "s1 = \"a quick brown fox jumps over the lazy dog\"\n",
    "s2 = \"dog the bounty hunter gave an interview to fox news\"\n",
    "s1 = \"I bought cheese burger from my mom's favorite restaurant\"\n",
    "s2 = \"beef sandwich is made by my mother\"\n",
    "print(nlp(s1).similarity(nlp(s2)))\n",
    "\n",
    "print(get_scores(s1, s2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0785)\n",
      "'fruit', 'herb spice', 0.1982\n",
      "'fruit', 'herb spice peppers', 0.1223\n",
      "'fruit', 'herb spice peppers pepper', 0.0354\n",
      "'fruit', 'meat', 0.6130\n",
      "'fruit', 'meat sausage', 0.3689\n",
      "'fruit', 'meat sausage pepperoni', 0.1651\n",
      "'fruit', 'staple', 0.2437\n",
      "'fruit', 'staple wheat', 0.0813\n",
      "'fruit', 'staple wheat pizza', 0.0007\n",
      "'fruit temperate', 'herb spice', 0.2265\n",
      "'fruit temperate', 'herb spice peppers', 0.1227\n",
      "'fruit temperate', 'herb spice peppers pepper', 0.0419\n",
      "'fruit temperate', 'meat', 0.3063\n",
      "'fruit temperate', 'meat sausage', 0.2764\n",
      "'fruit temperate', 'meat sausage pepperoni', 0.2212\n",
      "'fruit temperate', 'staple', 0.2162\n",
      "'fruit temperate', 'staple wheat', 0.0788\n",
      "'fruit temperate', 'staple wheat pizza', 0.0517\n",
      "'fruit temperate apple', 'herb spice', 0.2460\n",
      "'fruit temperate apple', 'herb spice peppers', 0.2058\n",
      "'fruit temperate apple', 'herb spice peppers pepper', 0.1837\n",
      "'fruit temperate apple', 'meat', 0.2252\n",
      "'fruit temperate apple', 'meat sausage', 0.3011\n",
      "'fruit temperate apple', 'meat sausage pepperoni', 0.3323\n",
      "'fruit temperate apple', 'staple', 0.1947\n",
      "'fruit temperate apple', 'staple wheat', 0.1516\n",
      "'fruit temperate apple', 'staple wheat pizza', 0.1084\n",
      "39    0.41717\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_10</th>\n",
       "      <th>item_20</th>\n",
       "      <th>item_l1</th>\n",
       "      <th>item_l2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Costco - Pepperoni Pizza</td>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>costco - pepperoni pizza</td>\n",
       "      <td>apple</td>\n",
       "      <td>[herb_spice, herb_spice__peppers, herb_spice__...</td>\n",
       "      <td>[fruit, fruit__temperate, fruit__temperate__ap...</td>\n",
       "      <td>[726, 744, 746, 762, 841, 847, 1103, 1147, 1199]</td>\n",
       "      <td>[661, 680, 681]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user                    item_1 item_2  rating                   item_10  \\\n",
       "39     1  Costco - Pepperoni Pizza  apple       1  costco - pepperoni pizza   \n",
       "\n",
       "   item_20                                            item_l1  \\\n",
       "39   apple  [herb_spice, herb_spice__peppers, herb_spice__...   \n",
       "\n",
       "                                              item_l2  \\\n",
       "39  [fruit, fruit__temperate, fruit__temperate__ap...   \n",
       "\n",
       "                                                  l1               l2  \n",
       "39  [726, 744, 746, 762, 841, 847, 1103, 1147, 1199]  [661, 680, 681]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging\n",
    "weighing='equal'\n",
    "\n",
    "def debug_pair_sim_scores(line, weight=weighing_scheme[weighing], sim_dict=sim_dict):    \n",
    "    if(len(line['l1'])==0) or (len(line['l2'])==0):\n",
    "        return 0\n",
    "    \n",
    "    j = line['l1']\n",
    "    j_prime = line['l2']\n",
    "    \n",
    "    if j_prime == j:\n",
    "        return 1\n",
    "    else:\n",
    "        curr_score = label_score(j_prime, j, weight, sim_dict=sim_dict)\n",
    "    return float(curr_score)\n",
    "\n",
    "temp_df = df[39:40]\n",
    "print(temp_df.apply(debug_pair_sim_scores, axis=1))\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2772.4561104774475\n"
     ]
    }
   ],
   "source": [
    "weighing='equal'\n",
    "col = 'hSim-1'\n",
    "\n",
    "def pair_sim_scores(line, weight=weighing_scheme[weighing], sim_dict=sim_dict):\n",
    "    if(len(line['l1'])==0) or (len(line['l2'])==0):\n",
    "        return 0\n",
    "    \n",
    "    j = line['l1']\n",
    "    j_prime = line['l2']\n",
    "\n",
    "    if j_prime == j:\n",
    "        return 1\n",
    "    else:\n",
    "        curr_score = label_score(j_prime, j, weight, sim_dict=sim_dict)\n",
    "    return float(curr_score)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "df[col] = df.apply(pair_sim_scores, axis=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.191934585571289\n"
     ]
    }
   ],
   "source": [
    "weighing='124'\n",
    "col = 'hSim-2'\n",
    "\n",
    "def pair_sim_scores(line, weight=weighing_scheme[weighing], sim_dict=sim_dict):\n",
    "    if(len(line['l1'])==0) or (len(line['l2'])==0):\n",
    "        return 0\n",
    "    \n",
    "    j = line['l1']\n",
    "    j_prime = line['l2']\n",
    "\n",
    "    if j_prime == j:\n",
    "        return 1\n",
    "    else:\n",
    "        curr_score = label_score(j_prime, j, weight, sim_dict=sim_dict)\n",
    "    return float(curr_score)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "df[col] = df.apply(pair_sim_scores, axis=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0926084518432617\n"
     ]
    }
   ],
   "source": [
    "weighing='freq'\n",
    "col = 'hSim-freq'\n",
    "\n",
    "def pair_sim_scores(line, weight=weighing_scheme[weighing], sim_dict=sim_dict):\n",
    "    if(len(line['l1'])==0) or (len(line['l2'])==0):\n",
    "        return 0\n",
    "\n",
    "    j = line['l1']\n",
    "    j_prime = line['l2']\n",
    "\n",
    "    if j_prime == j:\n",
    "        return 1\n",
    "    else:\n",
    "        curr_score = label_score(j_prime, j, weight, sim_dict=sim_dict)\n",
    "    return float(curr_score)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "df[col] = df.apply(pair_sim_scores, axis=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['hSim-1', 'hSim-2', 'hSim-freq']:\n",
    "#     df.loc[df[col]==-1.0, col] = np.nan\n",
    "    df.loc[df[col]==-1.0, col] = 0.0\n",
    "cols = ['user', 'item_1', 'item_2', 'rating', 'hSim-1', 'hSim-2', 'hSim-freq']\n",
    "df = df[cols]\n",
    "filename = substitution_rating_scores['hSim']\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(BERT_F1_dict_file, sim_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28 & 0.28 & 0.269 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_z</th>\n",
       "      <th>hSim-1</th>\n",
       "      <th>hSim-2</th>\n",
       "      <th>hSim-freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rating_z</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating_z  hSim-1  hSim-2  hSim-freq\n",
       "rating_z       1.0    0.28    0.28      0.269"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['rating_z','hSim-1', 'hSim-2', 'hSim-freq']\n",
    "dfs = []\n",
    "for u, df_temp in df.groupby('user'):\n",
    "    df_temp['rating_z'] = zscore(df_temp['rating'])\n",
    "    dfs.append(df_temp)\n",
    "d1_z = pd.concat(dfs)\n",
    "r2 = d1_z.dropna()[cols].corr().head(1).round(3)\n",
    "print(' & '.join([str(s) for s in r2.values[0][1:]]), '\\n')\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for metric, filename in substitution_rating_scores.items():\n",
    "    df_temp = pd.read_csv(filename)\n",
    "    cols = ['user', 'item_1', 'item_2', 'rating']\n",
    "    dfs.append(df_temp.set_index(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.concat(dfs, axis=1).reset_index().drop(columns=['Unnamed: 0'])\n",
    "df_all = pd.concat(dfs, axis=1).reset_index().drop(columns=['Unnamed: 0'])\n",
    "df_all.to_csv(substitution_score_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
